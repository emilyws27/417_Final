{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "data = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "#checking for null instances\n",
    "data = data.fillna(0)\n",
    "print(\"\\nNull Instances:\\n\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "#Getting the top features from the dataset\n",
    "top_features = SelectKBest(score_func=chi2, k=11)\n",
    "\n",
    "dfscores = pd.DataFrame(top_features.fit(X,y).scores_)  #Store predictor scores in a column \n",
    "dfcolumns = pd.DataFrame(X.columns)  #Store predictor variable names in a column\n",
    "\n",
    "#List of features with heaviest weight/importance\n",
    "predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "predScores.columns = ['Predictor','Score']   #naming the dataframe columns\n",
    "print(predScores.nlargest(11,'Score'))       #print top (by score) 10 features\n",
    "\n",
    "#Drop the bottom two features (smallest score)\n",
    "data = data.drop('density', axis=1)\n",
    "data = data.drop('pH', axis=1)\n",
    "\n",
    "X= data.loc[:, 'fixed acidity':'alcohol']\n",
    "y= data['quality']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=417)\n",
    "\n",
    "wine_dataset_file = \"winequality-red.csv\"\n",
    "\n",
    "full_df = pd.read_csv(wine_dataset_file, header = 0, delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best Random Forest Parameters: \", best_rf)\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"=====================RANDOM FOREST CLASSIFIER=====================\\n\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print('\\nClassification Report: \\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the ANN\n",
    "param_grid = {\n",
    "    'ann__hidden_layer_sizes': [(20,), (40,), (50,), (70,), (100,), (500,), (50, 50), (100, 100)],\n",
    "    'ann__activation': ['tanh', 'relu', 'logistic'],\n",
    "    'ann__solver': ['sgd', 'adam'],\n",
    "    'ann__alpha': [0.0001, 0.001, 0.01],\n",
    "    'ann__learning_rate': ['constant', 'adaptive'],\n",
    "    'ann__learning_rate_init' : [0.01, 0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"norm\", StandardScaler()),\n",
    "                 (\"ann\", MLPClassifier(max_iter=1000, random_state=42))])\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "\n",
    "pipe.set_params(**best_params)\n",
    "pipe.fit(X_train, y_train)\n",
    "# Predict the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"=====================ANN CLASSIFIER=====================\\n\")\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### HOW WE DID INITIAL TESTSING (AND GOT THE BEST OUTCOME)\n",
    "\n",
    "# wine_dataset_file = \"winequality-red.csv\"\n",
    "#\n",
    "# full_df = pd.read_csv(wine_dataset_file, header = 0, delimiter=\";\")\n",
    "#\n",
    "# X = full_df.iloc[:, :-1]\n",
    "# Y = full_df.iloc[:, -1]\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=417)\n",
    "#\n",
    "# train_score = []\n",
    "# test_score = []\n",
    "#\n",
    "# # more layers does not improve test data\n",
    "# layers = list(range(10,50,5))\n",
    "# for i in layers:\n",
    "#     # scaling / normalizing data helps increase test\n",
    "#     pipe = make_pipeline(StandardScaler(), MLPClassifier(activation = 'logistic',\n",
    "#                                                          solver = 'sgd',\n",
    "#                                                          hidden_layer_sizes = (i,), #tired multiple layers as well, cannot break ~ 0.60 for test\n",
    "#                                                          alpha=1e-2,\n",
    "#                                                          max_iter = 1000,\n",
    "#                                                          learning_rate_init = 0.2))\n",
    "#\n",
    "#     pipe.fit(X_train, y_train)\n",
    "#     train_score.append(pipe.score(X_train,y_train))\n",
    "#     test_score.append(pipe.score(X_test, y_test))\n",
    "#\n",
    "# plt.plot(layers,train_score,'.',label = 'train set')\n",
    "# plt.plot(layers,test_score,'-',label = 'test set')\n",
    "# plt.xlabel('layers')\n",
    "# plt.ylabel('score')\n",
    "# plt.legend()\n",
    "#\n",
    "# optimal_index = test_score.index(max(test_score))\n",
    "# print(f'Best number of hidden nodes: {layers[optimal_index]}, with a test accuracy of {test_score[optimal_index]}')\n",
    "#\n",
    "# non_norm = MLPClassifier(activation = 'logistic',\n",
    "#                          solver = 'sgd',\n",
    "#                          hidden_layer_sizes = (layers[optimal_index]), #tired multiple layers as well, cannot break ~ 0.60 for test\n",
    "#                          alpha=1e-2,\n",
    "#                          max_iter = 1000,\n",
    "#                          learning_rate_init = 0.2)\n",
    "#\n",
    "# non_norm.fit(X_train, y_train)\n",
    "# print(f'Non normalized test accuracy of {non_norm.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
