{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null Instances:\n",
      "\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "               Predictor        Score\n",
      "6   total sulfur dioxide  2755.557984\n",
      "5    free sulfur dioxide   161.936036\n",
      "10               alcohol    46.429892\n",
      "1       volatile acidity    15.580289\n",
      "2            citric acid    13.025665\n",
      "0          fixed acidity    11.260652\n",
      "9              sulphates     4.558488\n",
      "3         residual sugar     4.123295\n",
      "4              chlorides     0.752426\n",
      "8                     pH     0.154655\n",
      "7                density     0.000230\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "data = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "#checking for null instances\n",
    "data = data.fillna(0)\n",
    "print(\"\\nNull Instances:\\n\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "#Getting the top features from the dataset\n",
    "top_features = SelectKBest(score_func=chi2, k=11)\n",
    "\n",
    "dfscores = pd.DataFrame(top_features.fit(X,y).scores_)  #Store predictor scores in a column \n",
    "dfcolumns = pd.DataFrame(X.columns)  #Store predictor variable names in a column\n",
    "\n",
    "#List of features with heaviest weight/importance\n",
    "predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "predScores.columns = ['Predictor','Score']   #naming the dataframe columns\n",
    "print(predScores.nlargest(11,'Score'))       #print top (by score) 10 features\n",
    "\n",
    "#Drop the bottom two features (smallest score)\n",
    "data = data.drop('density', axis=1)\n",
    "data = data.drop('pH', axis=1)\n",
    "\n",
    "X= data.loc[:, 'fixed acidity':'alcohol']\n",
    "y= data['quality']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=417)\n",
    "\n",
    "wine_dataset_file = \"winequality-red.csv\"\n",
    "\n",
    "full_df = pd.read_csv(wine_dataset_file, header = 0, delimiter=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters:  RandomForestClassifier(min_samples_split=5)\n",
      "=====================RANDOM FOREST CLASSIFIER=====================\n",
      "\n",
      "Accuracy:  0.6116071428571429\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.65      0.76      0.70       461\n",
      "           6       0.57      0.63      0.60       455\n",
      "           7       0.64      0.32      0.43       151\n",
      "           8       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.61      1120\n",
      "   macro avg       0.39      0.30      0.31      1120\n",
      "weighted avg       0.59      0.61      0.59      1120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best Random Forest Parameters: \", best_rf)\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"=====================RANDOM FOREST CLASSIFIER=====================\\n\")\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print('\\nClassification Report: \\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "Best parameters found:  {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Accuracy:  0.5196428571428572\n",
      "Confusion Matrix: \n",
      " [[  0   0   4   2   0   0]\n",
      " [  0   0  28   8   0   0]\n",
      " [  0   0 314 147   0   0]\n",
      " [  0   0 187 267   1   0]\n",
      " [  0   0  34 116   1   0]\n",
      " [  0   0   5   6   0   0]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.55      0.68      0.61       461\n",
      "           6       0.49      0.59      0.53       455\n",
      "           7       0.50      0.01      0.01       151\n",
      "           8       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.52      1120\n",
      "   macro avg       0.26      0.21      0.19      1120\n",
      "weighted avg       0.49      0.52      0.47      1120\n",
      "\n",
      "=====================ANN CLASSIFIER=====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emily\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the ANN\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(MLPClassifier(max_iter=1000, random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "mlp = MLPClassifier(**best_params)\n",
    "mlp.fit(X_train, y_train)\n",
    "# Predict the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"=====================ANN CLASSIFIER=====================\\n\")\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "\n",
    "# X = full_df.iloc[:, :-1]\n",
    "# Y = full_df.iloc[:, -1]\n",
    "\n",
    "\n",
    "# train_score = []\n",
    "# test_score = []\n",
    "\n",
    "# # more layers does not improve test data\n",
    "# layers = list(range(10,50,5))\n",
    "# for i in layers:\n",
    "\n",
    "#     mlp = MLPClassifier(**best_params)\n",
    "#     # scaling / normalizing data helps increase test\n",
    "#     pipe = make_pipeline(StandardScaler(), mlp)\n",
    "\n",
    "#     pipe.fit(X_train, y_train)\n",
    "#     train_score.append(pipe.score(X_train,y_train))\n",
    "#     test_score.append(pipe.score(X_test, y_test))\n",
    "\n",
    "# plt.plot(layers,train_score,'.',label = 'train set')\n",
    "# plt.plot(layers,test_score,'-',label = 'test set')\n",
    "# plt.xlabel('layers')\n",
    "# plt.ylabel('score')\n",
    "# plt.legend()\n",
    "\n",
    "# y_pred = mlp.predict(X_test)\n",
    "\n",
    "# # Calculate the evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "\n",
    "# # Print the evaluation metrics\n",
    "# print(\"Classification Report: \\n\", report)\n",
    "\n",
    "# optimal_index = test_score.index(max(test_score))\n",
    "# print(f'Best number of hidden nodes: {layers[optimal_index]}, with a test accuracy of {test_score[optimal_index]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
